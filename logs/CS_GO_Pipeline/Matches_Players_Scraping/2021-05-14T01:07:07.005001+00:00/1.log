[2021-05-14 01:07:08,932] {taskinstance.py:877} INFO - Dependencies all met for <TaskInstance: CS_GO_Pipeline.Matches_Players_Scraping 2021-05-14T01:07:07.005001+00:00 [queued]>
[2021-05-14 01:07:08,948] {taskinstance.py:877} INFO - Dependencies all met for <TaskInstance: CS_GO_Pipeline.Matches_Players_Scraping 2021-05-14T01:07:07.005001+00:00 [queued]>
[2021-05-14 01:07:08,949] {taskinstance.py:1068} INFO - 
--------------------------------------------------------------------------------
[2021-05-14 01:07:08,949] {taskinstance.py:1069} INFO - Starting attempt 1 of 4
[2021-05-14 01:07:08,949] {taskinstance.py:1070} INFO - 
--------------------------------------------------------------------------------
[2021-05-14 01:07:08,960] {taskinstance.py:1089} INFO - Executing <Task(BashOperator): Matches_Players_Scraping> on 2021-05-14T01:07:07.005001+00:00
[2021-05-14 01:07:08,963] {standard_task_runner.py:52} INFO - Started process 87 to run task
[2021-05-14 01:07:08,966] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'CS_GO_Pipeline', 'Matches_Players_Scraping', '2021-05-14T01:07:07.005001+00:00', '--job-id', '45', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/csgo_pipeline.py', '--cfg-path', '/tmp/tmpuwlbmtsp', '--error-file', '/tmp/tmpjitze5ug']
[2021-05-14 01:07:08,967] {standard_task_runner.py:77} INFO - Job 45: Subtask Matches_Players_Scraping
[2021-05-14 01:07:09,005] {logging_mixin.py:104} INFO - Running <TaskInstance: CS_GO_Pipeline.Matches_Players_Scraping 2021-05-14T01:07:07.005001+00:00 [running]> on host b7f6ee627e07
[2021-05-14 01:07:09,052] {taskinstance.py:1283} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Filipe
AIRFLOW_CTX_DAG_ID=CS_GO_Pipeline
AIRFLOW_CTX_TASK_ID=Matches_Players_Scraping
AIRFLOW_CTX_EXECUTION_DATE=2021-05-14T01:07:07.005001+00:00
AIRFLOW_CTX_DAG_RUN_ID=manual__2021-05-14T01:07:07.005001+00:00
[2021-05-14 01:07:09,053] {bash.py:135} INFO - Tmp dir root location: 
 /tmp
[2021-05-14 01:07:09,054] {bash.py:158} INFO - Running command: cd /opt/airflow/scrapers && scrapy runspider match_players.py -o match_players.json
[2021-05-14 01:07:09,063] {bash.py:169} INFO - Output:
[2021-05-14 01:07:09,878] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: scrapybot)
[2021-05-14 01:07:09,885] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.2.0, Python 3.6.13 (default, Mar 27 2021, 03:29:33) - [GCC 8.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1k  25 Mar 2021), cryptography 3.4.7, Platform Linux-5.4.72-microsoft-standard-WSL2-x86_64-with-debian-10.8
[2021-05-14 01:07:09,885] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor
[2021-05-14 01:07:09,898] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.crawler] INFO: Overridden settings:
[2021-05-14 01:07:09,898] {bash.py:173} INFO - {'SPIDER_LOADER_WARN_ONLY': True}
[2021-05-14 01:07:09,912] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.extensions.telnet] INFO: Telnet Password: a53eae24e52ef6cb
[2021-05-14 01:07:09,972] {bash.py:173} INFO - 2021-05-14 01:07:09 [scrapy.middleware] INFO: Enabled extensions:
[2021-05-14 01:07:09,984] {bash.py:173} INFO - ['scrapy.extensions.corestats.CoreStats',
[2021-05-14 01:07:09,992] {bash.py:173} INFO -  'scrapy.extensions.telnet.TelnetConsole',
[2021-05-14 01:07:09,992] {bash.py:173} INFO -  'scrapy.extensions.memusage.MemoryUsage',
[2021-05-14 01:07:09,993] {bash.py:173} INFO -  'scrapy.extensions.feedexport.FeedExporter',
[2021-05-14 01:07:09,993] {bash.py:173} INFO -  'scrapy.extensions.logstats.LogStats']
[2021-05-14 01:07:10,043] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.middleware] INFO: Enabled downloader middlewares:
[2021-05-14 01:07:10,044] {bash.py:173} INFO - ['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
[2021-05-14 01:07:10,045] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
[2021-05-14 01:07:10,057] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
[2021-05-14 01:07:10,077] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
[2021-05-14 01:07:10,090] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.retry.RetryMiddleware',
[2021-05-14 01:07:10,106] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
[2021-05-14 01:07:10,126] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
[2021-05-14 01:07:10,154] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
[2021-05-14 01:07:10,155] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
[2021-05-14 01:07:10,157] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
[2021-05-14 01:07:10,158] {bash.py:173} INFO -  'scrapy.downloadermiddlewares.stats.DownloaderStats']
[2021-05-14 01:07:10,158] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.middleware] INFO: Enabled spider middlewares:
[2021-05-14 01:07:10,159] {bash.py:173} INFO - ['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
[2021-05-14 01:07:10,159] {bash.py:173} INFO -  'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
[2021-05-14 01:07:10,159] {bash.py:173} INFO -  'scrapy.spidermiddlewares.referer.RefererMiddleware',
[2021-05-14 01:07:10,159] {bash.py:173} INFO -  'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
[2021-05-14 01:07:10,160] {bash.py:173} INFO -  'scrapy.spidermiddlewares.depth.DepthMiddleware']
[2021-05-14 01:07:10,160] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.middleware] INFO: Enabled item pipelines:
[2021-05-14 01:07:10,160] {bash.py:173} INFO - []
[2021-05-14 01:07:10,160] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.core.engine] INFO: Spider opened
[2021-05-14 01:07:10,160] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
[2021-05-14 01:07:10,161] {bash.py:173} INFO - 2021-05-14 01:07:10 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6025
[2021-05-14 01:07:11,016] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.hltv.org/stats/matches?offset=93500> (failed 1 times): 429 Unknown Status
[2021-05-14 01:07:11,446] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://www.hltv.org/stats/matches?offset=93500> (failed 2 times): 429 Unknown Status
[2021-05-14 01:07:11,814] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying <GET https://www.hltv.org/stats/matches?offset=93500> (failed 3 times): 429 Unknown Status
[2021-05-14 01:07:11,815] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.core.engine] DEBUG: Crawled (429) <GET https://www.hltv.org/stats/matches?offset=93500> (referer: None)
[2021-05-14 01:07:11,916] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.spidermiddlewares.httperror] INFO: Ignoring response <429 https://www.hltv.org/stats/matches?offset=93500>: HTTP status code is not handled or not allowed
[2021-05-14 01:07:11,918] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.core.engine] INFO: Closing spider (finished)
[2021-05-14 01:07:11,920] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
[2021-05-14 01:07:11,921] {bash.py:173} INFO - {'downloader/request_bytes': 714,
[2021-05-14 01:07:11,921] {bash.py:173} INFO -  'downloader/request_count': 3,
[2021-05-14 01:07:11,922] {bash.py:173} INFO -  'downloader/request_method_count/GET': 3,
[2021-05-14 01:07:11,922] {bash.py:173} INFO -  'downloader/response_bytes': 11316,
[2021-05-14 01:07:11,922] {bash.py:173} INFO -  'downloader/response_count': 3,
[2021-05-14 01:07:11,922] {bash.py:173} INFO -  'downloader/response_status_count/429': 3,
[2021-05-14 01:07:11,923] {bash.py:173} INFO -  'elapsed_time_seconds': 1.85805,
[2021-05-14 01:07:11,923] {bash.py:173} INFO -  'finish_reason': 'finished',
[2021-05-14 01:07:11,923] {bash.py:173} INFO -  'finish_time': datetime.datetime(2021, 5, 14, 1, 7, 11, 918760),
[2021-05-14 01:07:11,924] {bash.py:173} INFO -  'httperror/response_ignored_count': 1,
[2021-05-14 01:07:11,924] {bash.py:173} INFO -  'httperror/response_ignored_status_count/429': 1,
[2021-05-14 01:07:11,924] {bash.py:173} INFO -  'log_count/DEBUG': 3,
[2021-05-14 01:07:11,925] {bash.py:173} INFO -  'log_count/ERROR': 1,
[2021-05-14 01:07:11,925] {bash.py:173} INFO -  'log_count/INFO': 11,
[2021-05-14 01:07:11,925] {bash.py:173} INFO -  'memusage/max': 116846592,
[2021-05-14 01:07:11,925] {bash.py:173} INFO -  'memusage/startup': 116846592,
[2021-05-14 01:07:11,926] {bash.py:173} INFO -  'response_received_count': 1,
[2021-05-14 01:07:11,926] {bash.py:173} INFO -  'retry/count': 2,
[2021-05-14 01:07:11,926] {bash.py:173} INFO -  'retry/max_reached': 1,
[2021-05-14 01:07:11,926] {bash.py:173} INFO -  'retry/reason_count/429 Unknown Status': 2,
[2021-05-14 01:07:11,927] {bash.py:173} INFO -  'scheduler/dequeued': 3,
[2021-05-14 01:07:11,927] {bash.py:173} INFO -  'scheduler/dequeued/memory': 3,
[2021-05-14 01:07:11,927] {bash.py:173} INFO -  'scheduler/enqueued': 3,
[2021-05-14 01:07:11,928] {bash.py:173} INFO -  'scheduler/enqueued/memory': 3,
[2021-05-14 01:07:11,928] {bash.py:173} INFO -  'start_time': datetime.datetime(2021, 5, 14, 1, 7, 10, 60710)}
[2021-05-14 01:07:11,928] {bash.py:173} INFO - 2021-05-14 01:07:11 [scrapy.core.engine] INFO: Spider closed (finished)
[2021-05-14 01:07:12,049] {bash.py:177} INFO - Command exited with return code 0
[2021-05-14 01:07:12,085] {taskinstance.py:1192} INFO - Marking task as SUCCESS. dag_id=CS_GO_Pipeline, task_id=Matches_Players_Scraping, execution_date=20210514T010707, start_date=20210514T010708, end_date=20210514T010712
[2021-05-14 01:07:12,118] {taskinstance.py:1246} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-05-14 01:07:12,162] {local_task_job.py:146} INFO - Task exited with return code 0
